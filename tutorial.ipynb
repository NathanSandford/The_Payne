{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** This file gives a brief overview of the capabilities of the code. **\n",
    "\n",
    "* If you want to predict the spectrum of a star with particular labels, you'll want the \"spectral_model\" package.\n",
    "* If you want to fit an observed spectrum, see the \"fitting\" package.\n",
    "* Downloading and processing APOGEE spectra is handled by the \"process_spectra\" package.\n",
    "* The \"utils\" package contains some general-purpose functions used by the other packages.\n",
    "* If you want to get under the hood and train your own models, there some functions in the train_NNs/ directory to get you started.\n",
    "\n",
    "The model interpolator requires you to pass it the trained neural network (really, a list of biases and weights parameterizing the network), so we read in the network we'll be using at the beginning and then pass it to various functions as we go. This is a bit cumbersome, but the advantage is that if you train a new network (with architechture compatible with the existing code) you can just pass it to the relevant functions without having to rewrite everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function # Python2 compatibility\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import utils\n",
    "import spectral_model\n",
    "import fitting\n",
    "\n",
    "# read in the standard wavelength grid onto which we interpolate spectra.\n",
    "wavelength = utils.load_wavelength_array()\n",
    "\n",
    "# read in the neural networks we'll need. \n",
    "NN_coeffs = utils.read_in_neural_network()\n",
    "w_array_0, w_array_1, w_array_2, b_array_0, b_array_1, b_array_2, x_min, x_max = NN_coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the data-driven spectral model to predict the APOGEE-like spectrum of a single star similar to the Sun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_err = 1e-2*np.ones(len(wavelength))\n",
    "\n",
    "# for a single-star model, the format of \"labels\" is [Teff, Logg, Vturb [km/s],\n",
    "#              [C/H], [N/H], [O/H], [Na/H], [Mg/H],\\\n",
    "#              [Al/H], [Si/H], [P/H], [S/H], [K/H],\\\n",
    "#              [Ca/H], [Ti/H], [V/H], [Cr/H], [Mn/H],\\\n",
    "#              [Fe/H], [Co/H], [Ni/H], [Cu/H], [Ge/H],\\\n",
    "#              C12/C13, Vmacro [km/s], radial velocity (RV)\n",
    "real_labels = scaled_labels = [5770, 4.44, 1.0,\\\n",
    "                               0., 0., 0., 0., 0.,\\\n",
    "                               0., 0., 0., 0., 0.,\\\n",
    "                               0., 0., 0., 0., 0.,\\\n",
    "                               0., 0., 0., 0., 0.,\\\n",
    "                               90., 6., 3.] # assuming RV = 3 km/s. \n",
    "\n",
    "# scale the labels (except for RV) the same as it was done during the training of the network\n",
    "scaled_labels[:-1] = (real_labels[:-1]-x_min)/(x_max-x_min) - 0.5\n",
    "print(np.array(scaled_labels).shape)\n",
    "\n",
    "real_spec = spectral_model.get_spectrum_from_neural_net(scaled_labels = scaled_labels[:-1], NN_coeffs = NN_coeffs)\n",
    "real_spec = utils.doppler_shift(wavelength, real_spec, scaled_labels[-1])\n",
    "\n",
    "# zoom in on a small region of the spectrum so we can see what's going on.\n",
    "lambda_min, lambda_max = 16000, 16100# for plotting \n",
    "m = (wavelength < lambda_max) & (wavelength > lambda_min)\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(wavelength[m], real_spec[m], 'k', lw=0.5)\n",
    "plt.xlim(lambda_min, lambda_max)\n",
    "plt.ylim(0.7, 1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add some noise to this model spectrum, and then fit it to see if we can recover the labels we put in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spec = real_spec + 0.01*np.random.randn(len(real_spec))\n",
    "\n",
    "tol = 5e-4 # tolerance for when the optimizer should stop optimizing.\n",
    "\n",
    "# assuming your NN has two hidden layers. \n",
    "w_array_0, w_array_1, w_array_2, b_array_0, b_array_1, b_array_2, x_min, x_max = NN_coeffs\n",
    "    \n",
    "def fit_func(dummy_variable, *labels):\n",
    "    norm_spec = spectral_model.get_spectrum_from_neural_net(scaled_labels = labels[:-1], \n",
    "            NN_coeffs = NN_coeffs)\n",
    "    norm_spec = utils.doppler_shift(wavelength, norm_spec, labels[-1])\n",
    "    return norm_spec\n",
    "    \n",
    "# if no initial guess is supplied\n",
    "# here we operate in the scaled label space\n",
    "p0 = np.zeros(26)\n",
    "        \n",
    "# don't allow the minimimizer to go outside the range of training set\n",
    "bounds = np.zeros((2,26))\n",
    "bounds[0,:] = -0.5\n",
    "bounds[1,:] = 0.5\n",
    "bounds[0,-1] = -5.\n",
    "bounds[1,-1] = 5.\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "popt, pcov = curve_fit(fit_func, xdata=[], ydata = data_spec, sigma = spec_err, p0 = p0,\n",
    "                bounds = bounds, ftol = tol, xtol = tol, absolute_sigma = True, method = 'trf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spec = real_spec + 0.01*np.random.randn(len(real_spec))\n",
    "\n",
    "popt, pcov, model_spec = fitting.fit_normalized_spectrum_single_star_model(norm_spec = data_spec, \n",
    "        spec_err = spec_err, NN_coeffs = NN_coeffs, p0 = None, mask_on = True, num_labels=26)\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "m = (wavelength < lambda_max) & (wavelength > lambda_min)\n",
    "plt.plot(wavelength[m], data_spec[m], 'k', lw=0.5, label = '\"data\" spec')\n",
    "plt.plot(wavelength[m], model_spec[m], 'r--', lw=0.5, label = 'best-fit model')\n",
    "plt.xlim(lambda_min, lambda_max)\n",
    "plt.legend(loc = 'best', frameon = False, fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that our best-fit labels are close to what we put in. \n",
    "print(popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've seen how to generate and fit model spectra, let's download an actual APOGEE spectrum. Here we'll download a \"combined\" spectrum. \n",
    "\n",
    "Note: downloading the spectra requires you to have Jo Bovy's Apogee package installed.\n",
    "\n",
    "Here we adopt the the DR12/13 reduction of APOGEE (v6.2). Edit os.environs in process_spectra source codes to download the latest version of APOGEE spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import process_spectra\n",
    "\n",
    "apogee_id = b'2M18513961+4338099'\n",
    "spec, spec_err = process_spectra.get_combined_spectrum_single_object(apogee_id = apogee_id, \n",
    "                    catalog = None, save_local = False)\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "m = (spec_err < 0.1) & (wavelength < lambda_max) & (wavelength > lambda_min)\n",
    "plt.plot(wavelength[m], spec[m], 'k', lw=0.5)\n",
    "plt.ylim(0.75, 1.05)\n",
    "plt.xlim(lambda_min, lambda_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit this spectrum with The-Payne-interpolated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, pcov, best_fit_spec = fitting.fit_normalized_spectrum_single_star_model(norm_spec = spec, \n",
    "        spec_err = spec_err, NN_coeffs = NN_coeffs, p0 = None, mask_on = True, num_labels=26)\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(wavelength[m], spec[m], 'k', lw=0.5, label = 'APOGEE spectrum')\n",
    "plt.plot(wavelength[m], best_fit_spec[m], 'r', lw=0.5, label = 'Best-fit model')\n",
    "plt.xlim(lambda_min, lambda_max)\n",
    "plt.ylim(0.7, 1.1)\n",
    "plt.legend(loc = 'best', frameon = False, fontsize= 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One practical note:**\n",
    "\n",
    "Fitting combined spectra with The Payne is pretty fast. If you pass the fitting function to a Python multiprocessing Pool, you should be able to comfortably fit 10,000 targets in < 1 day on a single node of a typical cluster. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
